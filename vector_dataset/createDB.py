import os
from langchain_community.document_loaders import TextLoader, PyPDFLoader, UnstructuredWordDocumentLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from huggingface_hub import login
from langchain_community.vectorstores import FAISS

""" è¼‰å…¥æª”æ¡ˆ

å°‡æ”¾åœ¨ ./uploaded_files ä¸­çš„æª”æ¡ˆè¼‰å…¥ï¼Œä¸¦å°‡å…¶è®€æˆdocuments
"""
BASE_DIR = os.path.dirname(__file__)


folder_path = os.path.join(BASE_DIR, 'uploaded_files')
documents = []
 
if not os.path.exists(folder_path):
    raise RuntimeError(f"{folder_path} not found")

for file in os.listdir(folder_path):
    path = os.path.join(folder_path, file)

    if file.endswith(".txt"):
        print(f"ğŸ“„ æ­£åœ¨å°å…¥ TXTï¼š{file}")
        loader = TextLoader(path, encoding="utf-8")
    elif file.endswith(".pdf"):
        print(f"ğŸ“• æ­£åœ¨å°å…¥ PDFï¼š{file}")
        loader = PyPDFLoader(path)
    elif file.endswith(".docx"):
        print(f"ğŸ“ æ­£åœ¨å°å…¥ DOCXï¼š{file}")
        loader = UnstructuredWordDocumentLoader(path)
    else:
        continue

    documents.extend(loader.load())


"""åˆ‡åˆ†æ–‡ä»¶
å°‡æª”æ¡ˆæ–‡ä»¶å…§å®¹ä¾ç…§chunk_sizeåšåˆ‡åˆ†ï¼Œä¸¦è¨­ç½®chunk_overlapä¿ç•™ä¸Šä¸‹æ–‡é—œä¿‚
"""

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
split_docs = splitter.split_documents(documents)

print(f"Loaded {len(documents)} documents")
print(f"Split into {len(split_docs)} chunks")

"""å‘é‡æ¨¡å‹
ä½¿ç”¨ HuggingFace çš„ embeddinggemma-300m æ¨¡å‹ç”¢ç”Ÿå‘é‡

"""

class EmbeddingGemmaEmbeddings(HuggingFaceEmbeddings):
    def __init__(self, **kwargs):
        super().__init__(
            model_name="google/embeddinggemma-300m",        # HF ä¸Šçš„å®˜æ–¹æ¨¡å‹
            encode_kwargs={"normalize_embeddings": True},   # ä¸€èˆ¬æª¢ç´¢æ…£ä¾‹
            **kwargs
        )

    # embedæˆå®˜æ–¹å»ºè­°çš„å‰ç¶´
    def embed_documents(self, texts):
        texts = [f'title: none | text: {t}' for t in texts]
        return super().embed_documents(texts)

    def embed_query(self, text):
        return super().embed_query(f'task: search result | query: {text}')

"""ç™»å…¥Huggin Face
é ˆè‡³ https://huggingface.co/ å‰µå»ºå¸³è™Ÿï¼Œä¸¦å‰å¾€setting/access tokené é¢
æŒ‰ä¸‹Create new Tokenï¼ŒToken Type ç‚º Readï¼Œå°‡tokenè¨­ç½®é“ç’°å¢ƒè®Šæ•¸ä¸­
ç™»å…¥å¾Œæ‰å¯ä»¥å°‡ embedding model å»ºç«‹èµ·ä¾†
"""

HF_TOKEN = os.environ.get("HUGGING_FACE_TOKEN")
if not HF_TOKEN:
    raise RuntimeError("HUGGING_FACE_TOKEN not set")

login(token=HF_TOKEN)


# å»ºç«‹å‘é‡è³‡æ–™åº«


embedding_model = EmbeddingGemmaEmbeddings()
vectorstore = FAISS.from_documents(split_docs, embedding_model)

# å„²å­˜å‘é‡è³‡æ–™åº«
vectorstore.save_local("faiss_db")